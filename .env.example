# Ollama
OLLAMA_BASE_URL=http://localhost:11434

# TEI (Text Embeddings Inference)
TEI_BASE_URL=http://localhost:8080

# vLLM (TEI가 지원하지 못하는 모델용, opt-in)
# VLLM_BASE_URL=http://localhost:8081
# VLLM_DEFAULT_MODEL=jinaai/jina-embeddings-v3
# VLLM_MODELS=jinaai/jina-embeddings-v3
# VLLM_DOCKER_IMAGE=vllm/vllm-openai:latest
# VLLM_CONTAINER_NAME=vllm-embeddings
# VLLM_SWAP_TIMEOUT=300
# VLLM_WSL_DISTRO=Ubuntu-24.04

# Gateway
GATEWAY_HOST=0.0.0.0
GATEWAY_PORT=8000

# Default models
OLLAMA_DEFAULT_MODEL=bge-m3
TEI_DEFAULT_MODEL=intfloat/multilingual-e5-large-instruct

# TEI dynamic model swapping (comma-separated)
TEI_MODELS=intfloat/multilingual-e5-base,intfloat/multilingual-e5-large-instruct,nlpai-lab/KURE-v1
TEI_DOCKER_IMAGE=ghcr.io/huggingface/text-embeddings-inference:89-1.9
TEI_SWAP_TIMEOUT=600
TEI_WSL_DISTRO=Ubuntu-24.04

# HuggingFace token (gated 모델 접근용)
# HF_TOKEN=hf_your_token_here
