# Ollama
OLLAMA_BASE_URL=http://localhost:11434

# TEI (Text Embeddings Inference)
TEI_BASE_URL=http://localhost:8080

# Gateway
GATEWAY_HOST=0.0.0.0
GATEWAY_PORT=8000

# Default models
OLLAMA_DEFAULT_MODEL=bge-m3
TEI_DEFAULT_MODEL=intfloat/multilingual-e5-large-instruct

# TEI dynamic model swapping (comma-separated)
TEI_MODELS=BAAI/bge-m3,Qwen/Qwen3-Embedding-0.6B,Qwen/Qwen3-Embedding-4B,google/embeddinggemma-300m,nomic-ai/nomic-embed-text-v1.5,nomic-ai/nomic-embed-text-v2-moe,Snowflake/snowflake-arctic-embed-l-v2.0,intfloat/multilingual-e5-base,intfloat/multilingual-e5-large-instruct,nlpai-lab/KURE-v1,jinaai/jina-embeddings-v5-text-small-retrieval
TEI_DOCKER_IMAGE=ghcr.io/huggingface/text-embeddings-inference:89-1.9
TEI_SWAP_TIMEOUT=120
TEI_WSL_DISTRO=Ubuntu-24.04

# HuggingFace token (gated 모델 접근용: google/embeddinggemma-300m 등)
# HF_TOKEN=hf_your_token_here
